---
# Galaxy
galaxy_create_user: true # False by default, as e.g. you might have a 'galaxy' user provided by LDAP or AD.
galaxy_separate_privileges: true # Best practices for security, configuration is owned by 'root' (or a different user) than the processes
galaxy_manage_paths: true # False by default as your administrator might e.g. have root_squash enabled on NFS. Here we can create the directories so it's fine.
galaxy_manage_cleanup: true
galaxy_layout: root-dir
galaxy_root: /data/galaxy/galaxy
galaxy_user: {name: "{{ galaxy_user_name }}", shell: /bin/bash}
galaxy_commit_id: release_24.1
galaxy_force_checkout: true
miniconda_prefix: "{{ galaxy_tool_dependency_dir }}/_conda"
miniconda_version: 23.9
miniconda_channels: ['conda-forge', 'defaults']

# Galaxy Job Configuration
galaxy_job_config:
  runners:
    local_runner:
      load: galaxy.jobs.runners.local:LocalJobRunner
      workers: 4
    slurm:
      load: galaxy.jobs.runners.slurm:SlurmJobRunner
      drmaa_library_path: /usr/lib/slurm-drmaa/lib/libdrmaa.so.1
      workers: 4
  handling:
    assign: ['db-skip-locked']
  execution:
    default: slurm
    environments:
      local_env:
        runner: local_runner
        tmp_dir: true
      slurm:
        runner: slurm
        native_specification: '--nodes=1 --ntasks=1 --cpus-per-task=1 --mem=4000'
        tmp_dir: true
      slurm100G:
        runner: slurm
        native_specification: '--nodes=1 --ntasks=1 --cpus-per-task=1 --mem=100000'
        tmp_dir: true
      slurm4c:
        runner: slurm
        tags: [4cores]
        native_specification: '--nodes=1 --ntasks=1 --cpus-per-task=4 --mem=20000'
        tmp_dir: true
      slurm4cLM:
        runner: slurm
        tags: [4cores]
        native_specification: '--nodes=1 --ntasks=1 --cpus-per-task=4 --mem=50000'
        tmp_dir: true
      slurm8c:
        runner: slurm
        native_specification: '--nodes=1 --ntasks=1 --cpus-per-task=8 --mem=20000'
        tmp_dir: true
      slurm16c:
        runner: slurm
        native_specification: '--nodes=1 --ntasks=1 --cpus-per-task=16 --mem=20000'
        tmp_dir: true
  limits:
  -
    # The number of jobs a user can have active in the specified
    # environment, or across all environments identified by the
    # specified tag. (formerly: concurrent_jobs)
    type: environment_user_concurrent_jobs
    id: slurm8c
    value: 3

  -
    type: environment_user_concurrent_jobs
    tag: 4cores
    value: 6

  tools:
  - id: bowtie2
    environment: slurm4c
  - id: cite_seq_count
    environment: slurm4c
  - id: cufflinks
    environment: slurm4c
  - id: cutadapt
    environment: slurm4c
  - id: hicup_hicup
    environment: slurm8c
  - id: hicup_mapper
    environment: slurm8c
  - id: omero_hyperstack_to_gastruloid_measurements
    environment: slurm8c
  - id: rna_star
    environment: slurm4cLM
  - id: rna_starsolo
    environment: slurm4cLM
  - id: rna_star_index_builder_data_manager
    environment: slurm4cLM
  - id: bedtools_coveragebed
    environment: slurm100G
  - id: bwa_mem_index_builder_data_manager
    environment: slurm4c
  - id: bwa
    environment: slurm4c
  - id: bwa_mem
    environment: slurm4c

galaxy_config:
  galaxy:
    brand: "Galaxyduboule"
    welcome_url: "/{{ grafana_hash }}/grafana/d/c61Pj2yGz/main?orgId=1" # This corresponds to the main dashboard
    admin_users:
    - lucille.delisle@epfl.ch
    database_connection: "postgresql:///{{ galaxy_db_name }}?host=/var/run/postgresql"
    file_path: /data/galaxy/data
    check_migrate_tools: false
    tool_data_path: "{{ galaxy_mutable_data_dir }}/tool-data"
    job_config:  "{{ galaxy_job_config }}" # Use the variable we defined above
    tool_sheds_config_file: "{{ galaxy_config_dir }}/tool_sheds_conf.xml"
    tool_config_file: "{{ galaxy_config_dir }}/tool_conf.xml,{{ galaxy_shed_tool_conf_file }}" # Use both customized tool_conf and shed_tool_conf
    user_preferences_extra_conf_path: "{{ galaxy_config_dir }}/user_preferences_extra_conf.yml"
    nginx_x_accel_redirect_base: /_x_accel_redirect # nginx will serve the files at download
    statsd_host: localhost
    statsd_influxdb: true
    smtp_server: localhost # Use a local smtp server to be able to send email without specifying the password
    smtp_ssl: false
    error_email_to: lucille.delisle@epfl.ch
    email_from: 'Lucille Delisle (galaxy) <lucille.delisle@epfl.ch>'
    library_import_dir: /data/mount_s3
    user_library_import_dir: /data/mount_s3/perso_storage
    allow_library_path_paste: true
    require_login: true # Only users can use galaxy
    allow_user_creation: false # Only the admins can create users
    allow_user_deletion: true
    expose_dataset_path: true # Users will see the path and the command lines
    ftp_upload_dir: /data/galaxy/uploads
    ftp_upload_site: galaxyduboule
    ftp_upload_purge: false # The ftp is not automatically purged on import.
    builds_file_path: "{{ galaxy_config_dir }}/builds.txt" # in order to only use the installed genomes a minimal build file is provided
    sanitize_all_html: false # Allow to see html pages in galaxy
    conda_ensure_channels: conda-forge,bioconda,defaults,pytorch,ilastik-forge
    expose_potentially_sensitive_job_metrics: true
    allow_user_impersonation: true
    allow_user_dataset_purge: true
  gravity:
    process_manager: systemd
    galaxy_root: "{{ galaxy_root }}/server"
    galaxy_user: "{{ galaxy_user_name }}"
    virtualenv: "{{ galaxy_venv_dir }}"
    gunicorn:
      # listening options
      bind: "unix:{{ galaxy_mutable_config_dir }}/gunicorn.sock"
      # performance options
      workers: 2
      # Other options that will be passed to gunicorn
      # This permits setting of 'secure' headers like REMOTE_USER (and friends)
      # https://docs.gunicorn.org/en/stable/settings.html#forwarded-allow-ips
      extra_args: '--forwarded-allow-ips="*"'
      # This lets Gunicorn start Galaxy completely before forking which is faster.
      # https://docs.gunicorn.org/en/stable/settings.html#preload-app
      preload: true
    celery:
      concurrency: 2
      loglevel: DEBUG
    handlers:
      handler:
        processes: 2
        pools:
          - job-handlers
          - workflow-schedulers

# specifies config files to copy from the playbook
galaxy_config_files:
  - src: files/galaxy/config/builds.txt # in order to only use the installed genomes a minimal build file is provided
    dest: "{{ galaxy_config.galaxy.builds_file_path }}"
  - src: files/galaxy/config/tool_sheds_conf.xml # to be able to install tools from testtoolshed
    dest: "{{ galaxy_config.galaxy.tool_sheds_config_file }}"
  - src: files/galaxy/config/user_preferences_extra_conf.yml
    dest: "{{ galaxy_config.galaxy.user_preferences_extra_conf_path }}"

galaxy_config_templates:
  - src: templates/galaxy/config/tool_conf.xml.j2
    dest: "{{ galaxy_config_dir }}/tool_conf.xml"

galaxy_local_tools:
  - splitbedGraphFromBed
  - ScaleBedGraph


# NGINX
nginx_selinux_allow_local_connections: true
nginx_servers:
  - redirect-ssl
nginx_ssl_servers:
  - galaxy
nginx_enable_default_server: false
nginx_conf_http:
  client_max_body_size: 1g # This increases the upload size
  # gzip: "on" # This is enabled by default in Ubuntu, and the duplicate directive will cause a crash.
  gzip_proxied: "any"
  gzip_static: "on"   # The ngx_http_gzip_static_module module allows sending precompressed files with the ".gz" filename extension instead of regular files.
  gzip_vary: "on"
  gzip_min_length: 128
  gzip_comp_level: 6  # Tradeoff of better compression for slightly more CPU time.
  gzip_types: |
      text/plain
      text/css
      text/xml
      text/javascript
      application/javascript
      application/x-javascript
      application/json
      application/xml
      application/xml+rss
      application/xhtml+xml
      application/x-font-ttf
      application/x-font-opentype
      image/png
      image/svg+xml
      image/x-icon
# The SV-IT is in charge of the certificate
# nginx_conf_ssl_certificate: galaxyduboule.epfl.ch.pem # This file must be in files/ssl/
# nginx_conf_ssl_certificate_key: galaxyduboule.epfl.ch.key # This is the name of the destination
# sslkeys: "{{ vault_sslkeys }}"

# Slurm
slurm_roles: ['controller', 'exec'] # Which roles should the machine play? exec are execution hosts.
slurm_nodes:
  - name: localhost    # Name of our host
    CPUs: 29           # htop gives 32 -> maybe should be 30 -> following the disaster of March 18th I put 28 to be on the safe side -> 20230515 I put 29 -> 20231207 I put 27
    RealMemory: 380000 # htop gives 386942MB -> I put 385000 -> following the disaster of March 18th I put 380000 to be on the safe side
    ThreadsPerCore: 1
slurm_partitions:
  - name: main
    Nodes: localhost
    Default: YES
slurm_config:
  SlurmdParameters: config_overrides   # Ignore errors if the host actually has cores != 2
  SelectType: select/cons_tres
  SelectTypeParameters: CR_CPU_Memory  # Allocate individual cores/memory instead of entire node

# Telegraf for grafana
telegraf_plugins_default:
  - plugin: disk
    tags:
      - diskmetrics = "true"
    tagpass:
      - path = [ "/data" ] # Which are the path to explore
  - plugin: cpu
    config:
      - percpu = true
  - plugin: mem
telegraf_plugins_extra:
  listen_galaxy_routes:
    plugin: "statsd"
    config:
      - service_address = ":8125"
      - metric_separator = "."
      - allowed_pending_messages = 10000
  monitor_galaxy_queue:
    plugin: "exec"
    config:
      - commands = ["/usr/bin/env PGDATABASE=galaxy /usr/local/bin/gxadmin iquery queue-overview --short-tool-id"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "15s"
  monitor_galaxy_user_disk_usage:
    plugin: "exec"
    config:
      - commands = ["/usr/bin/env PGDATABASE=galaxy /usr/local/bin/gxadmin iquery user-disk-usage --use-precalc"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "15s"

# # Proftpd:
# proftpd_galaxy_auth: yes
# galaxy_ftp_upload_dir: "{{ galaxy_config.galaxy.ftp_upload_dir }}"
# proftpd_display_connect: |
#   {{ inventory_hostname }} FTP server

#   Unauthorized access is prohibited
# proftpd_options:
#   - User: galaxy
#   - Group: galaxy
# proftpd_sql_db: galaxy@/var/run/postgresql
# proftpd_sql_user: galaxy
# proftpd_conf_ssl_certificate: /etc/nginx/ssl/galaxyduboule.epfl.ch.pem # These files were uploaded by the SV-IT
# proftpd_conf_ssl_certificate_key: /etc/nginx/ssl/galaxyduboule.epfl.ch.key # These files were uploaded by the SV-IT
# proftpd_global_options:
#   - PassivePorts: 30000 40000
# proftpd_use_mod_tls_shmcache: false # New option to not use this module
# proftpd_tls_options: NoSessionReuseRequired # Option to allow filezilla to work...
